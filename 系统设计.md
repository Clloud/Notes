# 海量数据处理

海量数据处理中常用的数据结构有：
- 哈希表 (HashMap)
- 堆 (Heap)
- 前缀树 (Trie)
- 位图 (BitMap)
- 布隆过滤器 (Bloom Filter).

> 1. 统计一万个单词中出现最频繁的前10个单词。

- 可以使用前缀树`Trie`统计每个单词出现的次数
- 使用小顶堆计算出现最频繁的10个单词



> 2. 搜索引擎会记录用户的查询串，每个查询串的长度为1-255字节。目前有1000万条查询串，这些记录重复度比较高，去重后不超过300万条。一个查询串的重复度越高就越热门。请统计最热门的10个查询串，要求使用的内存不能超过1G。

300万 * 255字节 = 765M，不会超过1G

- 可以使用哈希表统计每个查询串出现次数
- 使用小顶堆统计结果



> 3. 统计100亿个IP中出现次数最多的前10个IP.

每个IP地址是一个32位二进制数，占4字节，100亿个IP大约占用37G的空间，需要采用`MapReduce`的思想分批处理。

- **分割任务**：设计一个哈希函数（例如`f(IP) = IP % 100`），将100亿个IP分成100份
- **计算子任务**：使用小顶堆计算每份IP中出现次数最多的前10个IP
- **合并**：将100个子任务的计算结果进行合并，使用小顶堆计算最终结果



> 4. 在2.5亿个整数中找出不重复的整数。

- 对每一个整数使用 2 bit来表示它出现的次数：00-不存在，01-出现一次，10-出现多次，11-无意义
- 扫描这2.5亿个整数，修改Bitmap中相应位：如果是00变01，01变10，10保持不变
- 扫描完成后，将Bitmap中对应位是01的整数输出即可



> 5. A、B两个文件中各存放50亿条URL，每条URL占用64字节，内存限制是16G，请找出A、B文件共同的URL.

[Probabilistic Data structures: Bloom filter](https://hackernoon.com/probabilistic-data-structures-bloom-filter-5374112a7832)
[详解布隆过滤器的原理、使用场景和注意事项](https://www.jianshu.com/p/2104d11ee0a2)

假设布隆过滤器的错误率p为0.01，则位数组大小m约为输入元素个数n的10倍，50亿 * 10个Bit大约占用6.25G (计算公式请参考上面的文章)

- 使用A文件建立布隆过滤器
- 遍历B文件中的每一个元素，判断是否在A中出现过



